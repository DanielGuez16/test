#!/usr/bin/env python3
#run.py
"""
Steering ALM Metrics - Version avec Templates
============================================

Application FastAPI utilisant un syst√®me de templates Jinja2
pour s√©parer la logique m√©tier de la pr√©sentation.
"""

from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Request
from fastapi.responses import HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import pandas as pd
import uvicorn
import uuid
import logging
from pathlib import Path
from datetime import datetime

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Cr√©ation de l'application FastAPI
app = FastAPI(title="Steering ALM Metrics", version="2.0.0")

# Configuration CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Cr√©ation des dossiers requis
required_dirs = ["data", "templates", "static", "static/js", "static/css"]
for directory in required_dirs:
    Path(directory).mkdir(exist_ok=True)

# Configuration des fichiers statiques et templates
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# Variables globales pour la session (en production: utiliser une base de donn√©es)
file_session = {"files": {}}


#######################################################################################################################################

#                           API

#######################################################################################################################################


@app.get("/", response_class=HTMLResponse)
async def root(request: Request):
    """
    Page d'accueil de l'application
    
    Utilise le template Jinja2 pour s√©parer la pr√©sentation
    de la logique m√©tier.
    """
    try:
        return templates.TemplateResponse("index.html", {
            "request": request,
            "title": "Steering ALM Metrics",
            "version": "2.0.0",
            "timestamp": datetime.now().isoformat()
        })
    except Exception as e:
        logger.error(f"Erreur chargement template: {e}")
        # Fallback en cas d'erreur de template
        return HTMLResponse(content="""
            <html>
                <body style="font-family: Arial; padding: 50px; text-align: center;">
                    <h1>Steering ALM Metrics</h1>
                    <p style="color: red;">Erreur de chargement du template</p>
                    <p>V√©rifiez que le fichier templates/index.html existe</p>
                </body>
            </html>
        """)

@app.get("/health")
async def health_check():
    """Endpoint de v√©rification de l'√©tat de l'application"""
    return {
        "status": "healthy",
        "service": "steering-alm-metrics",
        "version": "2.0.0",
        "timestamp": datetime.now().isoformat(),
        "active_files": len(file_session.get("files", {})),
        "templates_available": Path("templates/index.html").exists(),
        "static_available": Path("static/js/main.js").exists()
    }

@app.post("/api/upload")
async def upload_file(file: UploadFile = File(...), file_type: str = Form(...)):
    """
    Endpoint d'upload des fichiers Excel
    
    Args:
        file: Fichier Excel upload√©
        file_type: Type de fichier ('j' ou 'jMinus1')
    
    Returns:
        R√©ponse JSON avec les informations du fichier trait√©
    """
    try:
        logger.info(f"üì§ Upload re√ßu: {file.filename}, type: {file_type}")
        
        # Validation du fichier
        if not file.filename:
            raise HTTPException(status_code=400, detail="Nom de fichier manquant")
        
        if not file.filename.lower().endswith(('.xlsx', '.xls')):
            raise HTTPException(
                status_code=400, 
                detail="Format non support√©. Seuls les fichiers Excel (.xlsx, .xls) sont accept√©s."
            )

        # Lecture et sauvegarde du fichier
        contents = await file.read()
        unique_filename = f"{file_type}_{uuid.uuid4().hex[:8]}_{file.filename}"
        file_path = Path("data") / unique_filename
        
        with open(file_path, "wb") as f:
            f.write(contents)
        
        logger.info(f"üíæ Fichier sauvegard√©: {file_path}")
        
        # Validation et analyse pr√©liminaire du fichier Excel
        try:
            df = pd.read_excel(file_path, engine='openpyxl')
            df.columns = df.columns.astype(str).str.strip()
            
            # V√©rification des colonnes requises
            required_columns = ["Top Conso", "R√©affectation", "Groupe De Produit", "Nominal Value"]
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                logger.warning(f"‚ö†Ô∏è Colonnes manquantes dans {file.filename}: {missing_columns}")
            
            logger.info(f"‚úÖ Excel valid√©: {len(df)} lignes, {len(df.columns)} colonnes")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lecture Excel: {e}")
            # Supprimer le fichier en cas d'erreur
            file_path.unlink(missing_ok=True)
            raise HTTPException(
                status_code=422, 
                detail=f"Fichier Excel invalide ou corrompu: {str(e)}"
            )
        
        # Stockage des informations du fichier
        file_session["files"][file_type] = {
            "filename": unique_filename,
            "original_name": file.filename,
            "rows": len(df),
            "columns": len(df.columns),
            "upload_time": datetime.now().isoformat(),
            "missing_columns": missing_columns
        }
        
        return {
            "success": True,
            "message": f"Fichier {file_type} trait√© avec succ√®s",
            "filename": file.filename,
            "rows": len(df),
            "columns": len(df.columns),
            "file_size": len(contents),
            "missing_columns": missing_columns
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur inattendue lors de l'upload: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

@app.post("/api/analyze")
async def analyze_files():
    """
    Endpoint d'analyse des fichiers LCR - Version compl√®te avec Balance Sheet et Consumption
    """
    try:
        logger.info("üîç D√©but de l'analyse Balance Sheet + Consumption")
        
        # V√©rification de la pr√©sence des deux fichiers
        if len(file_session.get("files", {})) < 2:
            raise HTTPException(
                status_code=400, 
                detail="Les deux fichiers (J et J-1) sont requis pour l'analyse"
            )
        
        if "j" not in file_session["files"] or "jMinus1" not in file_session["files"]:
            raise HTTPException(
                status_code=400,
                detail="Fichiers manquants. Veuillez uploader le fichier J et le fichier J-1"
            )
        
        # Chargement des fichiers
        dataframes = {}
        for file_type, file_info in file_session["files"].items():
            file_path = Path("data") / file_info["filename"]
            
            if not file_path.exists():
                raise HTTPException(
                    status_code=404,
                    detail=f"Fichier {file_type} non trouv√© sur le serveur"
                )
            
            df = pd.read_excel(file_path, engine='openpyxl')
            df.columns = df.columns.astype(str).str.strip()
            dataframes[file_type] = df
            
            logger.info(f"üìä {file_type}: {len(df)} lignes charg√©es")
        
        # G√©n√©ration du tableau crois√© dynamique Balance Sheet
        balance_sheet_results = create_balance_sheet_pivot_table(dataframes)
        
        # G√©n√©ration de l'analyse Consumption
        consumption_results = create_consumption_analysis_grouped_only(dataframes)
        
        logger.info("‚úÖ Analyses Balance Sheet et Consumption termin√©es avec succ√®s")
        
        return {
            "success": True,
            "message": "Analyses Balance Sheet et Consumption termin√©es",
            "timestamp": datetime.now().isoformat(),
            "results": {
                "balance_sheet": balance_sheet_results,
                "consumption": consumption_results
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'analyse: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur d'analyse: {str(e)}")

#######################################################################################################################################

#                           BALANCE SHEET

#######################################################################################################################################

def create_balance_sheet_pivot_table(dataframes):
    """
    Cr√©e le tableau crois√© dynamique Balance Sheet
    
    Args:
        dataframes: Dict contenant les DataFrames 'j' et 'jMinus1'
    
    Returns:
        Dict contenant les r√©sultats de l'analyse
    """
    try:
        logger.info("üíº Cr√©ation du TCD Balance Sheet")
        
        pivot_tables = {}
        totals_summary = {}
        
        # Traitement de chaque fichier
        for file_type, df in dataframes.items():
            logger.info(f"üîÑ Traitement du fichier {file_type}")
            
            # Filtrage des donn√©es
            df_filtered = df[df["Top Conso"] == "O"].copy()
            logger.info(f"üìã Apr√®s filtrage Top Conso='O': {len(df_filtered)} lignes")
            
            if len(df_filtered) == 0:
                logger.warning(f"‚ö†Ô∏è Aucune donn√©e avec Top Conso='O' pour {file_type}")
                continue
            
            # Pr√©paration des colonnes
            df_filtered["Nominal Value"] = pd.to_numeric(
                df_filtered["Nominal Value"], errors='coerce'
            ).fillna(0)
            
            df_filtered["R√©affectation"] = df_filtered["R√©affectation"].astype(str).str.upper().str.strip()
            
            # Filtrage ACTIF/PASSIF uniquement
            df_filtered = df_filtered[
                df_filtered["R√©affectation"].isin(["ACTIF", "PASSIF"])
            ].copy()
            
            logger.info(f"üìä Apr√®s filtrage ACTIF/PASSIF: {len(df_filtered)} lignes")
            logger.info(f"üè∑Ô∏è R√©affectations trouv√©es: {sorted(df_filtered['R√©affectation'].unique())}")
            
            if len(df_filtered) == 0:
                logger.warning(f"‚ö†Ô∏è Aucune donn√©e ACTIF/PASSIF pour {file_type}")
                continue
            
            # Cr√©ation du tableau crois√© dynamique
            pivot_table = pd.pivot_table(
                df_filtered,
                index="Groupe De Produit",
                columns="R√©affectation",
                values="Nominal Value",
                aggfunc="sum",
                fill_value=0,
                margins=True,
                margins_name="TOTAL"
            )
            
            # Conversion en milliards d'euros
            pivot_table = (pivot_table / 1_000_000_000).round(2)
            
            # Assurer la pr√©sence des colonnes ACTIF et PASSIF
            for col in ["ACTIF", "PASSIF"]:
                if col not in pivot_table.columns:
                    pivot_table[col] = 0.0
            
            # R√©organisation des colonnes
            pivot_table = pivot_table[["ACTIF", "PASSIF"]]
            
            pivot_tables[file_type] = pivot_table
            
            # Calcul des totaux
            if "TOTAL" in pivot_table.index:
                totals_summary[file_type] = {
                    "ACTIF": float(pivot_table.loc["TOTAL", "ACTIF"]),
                    "PASSIF": float(pivot_table.loc["TOTAL", "PASSIF"])
                }
            
            logger.info(f"‚úÖ TCD {file_type} cr√©√©: {pivot_table.shape[0]} lignes x {pivot_table.shape[1]} colonnes")
        
        # G√©n√©ration du HTML du tableau combin√©
        pivot_html = generate_pivot_table_html(pivot_tables)
        
        # Calcul des variations
        variations = calculate_variations(totals_summary)
        
        # G√©n√©ration du r√©sum√© ex√©cutif
        summary = generate_executive_summary(variations)
        
        return {
            "title": "Balance Sheet",
            "pivot_table_html": pivot_html,
            "variations": variations,
            "summary": summary,
            "metadata": {
                "analysis_date": datetime.now().isoformat(),
                "filters_applied": {
                    "top_conso": "O",
                    "reaffectation": ["ACTIF", "PASSIF"]
                },
                "files_analyzed": list(pivot_tables.keys())
            }
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur cr√©ation TCD: {e}")
        return {
            "title": "Balance Sheet - Erreur",
            "error": str(e),
            "pivot_table_html": "<p class='text-danger'>Erreur lors de la g√©n√©ration du tableau</p>"
        }

def generate_pivot_table_html(pivot_tables):
    """
    G√©n√®re le HTML du tableau crois√© dynamique combin√©
    
    Args:
        pivot_tables: Dict des tables pivot par type de fichier
    
    Returns:
        String HTML du tableau format√©
    """
    if len(pivot_tables) < 2:
        return "<div class='alert alert-warning'>Donn√©es insuffisantes pour g√©n√©rer le TCD complet</div>"
    
    pivot_j = pivot_tables.get("j")
    pivot_j1 = pivot_tables.get("jMinus1")
    
    if pivot_j is None or pivot_j1 is None:
        return "<div class='alert alert-danger'>Erreur: donn√©es manquantes pour la comparaison</div>"
    
    # Liste des groupes de produits (sans TOTAL pour l'instant)
    all_products = sorted([p for p in set(pivot_j.index) | set(pivot_j1.index) if p != "TOTAL"])
    all_products.append("TOTAL")  # Ajouter TOTAL √† la fin
    
    html = """
    <table class="table table-bordered pivot-table">
        <thead>
            <tr>
                <th rowspan="2" class="align-middle">Groupe De Produit</th>
                <th colspan="2" class="text-center header-j-minus-1">J-1 (Hier)</th>
                <th colspan="2" class="text-center header-j">J (Aujourd'hui)</th>
                <th colspan="2" class="text-center header-variation">Variation (J - J-1)</th>
            </tr>
            <tr>
                <th class="text-center header-j-minus-1">ACTIF</th>
                <th class="text-center header-j-minus-1">PASSIF</th>
                <th class="text-center header-j">ACTIF</th>
                <th class="text-center header-j">PASSIF</th>
                <th class="text-center header-variation">ACTIF</th>
                <th class="text-center header-variation">PASSIF</th>
            </tr>
        </thead>
        <tbody>
    """
    
    # G√©n√©ration des lignes
    for product in all_products:
        css_class = "total-row" if product == "TOTAL" else ""
        html += f'<tr class="{css_class}">'
        html += f'<td class="fw-bold">{product}</td>'
        
        # Valeurs J-1
        for category in ["ACTIF", "PASSIF"]:
            value_j1 = pivot_j1.loc[product, category] if product in pivot_j1.index else 0.0
            html += f'<td class="text-end numeric-value">{value_j1:.2f}</td>'
        
        # Valeurs J
        for category in ["ACTIF", "PASSIF"]:
            value_j = pivot_j.loc[product, category] if product in pivot_j.index else 0.0
            html += f'<td class="text-end numeric-value">{value_j:.2f}</td>'
        
        # Variations
        for category in ["ACTIF", "PASSIF"]:
            value_j1 = pivot_j1.loc[product, category] if product in pivot_j1.index else 0.0
            value_j = pivot_j.loc[product, category] if product in pivot_j.index else 0.0
            variation = value_j - value_j1
            
            css_class = "variation-positive" if variation > 0 else "variation-negative" if variation < 0 else ""
            sign = "+" if variation > 0 else ""
            html += f'<td class="text-end numeric-value {css_class}">{sign}{variation:.2f}</td>'
        
        html += '</tr>'
    
    html += """
        </tbody>
    </table>
    """
    
    return html

def calculate_variations(totals_summary):
    """
    Calcule les variations entre J et J-1
    
    Args:
        totals_summary: Dict des totaux par fichier
    
    Returns:
        Dict des variations calcul√©es
    """
    if "j" not in totals_summary or "jMinus1" not in totals_summary:
        return {}
    
    variations = {}
    for category in ["ACTIF", "PASSIF"]:
        j_value = totals_summary["j"].get(category, 0)
        j1_value = totals_summary["jMinus1"].get(category, 0)
        
        variations[category] = {
            "j_minus_1": round(j1_value, 2),
            "j": round(j_value, 2),
            "variation": round(j_value - j1_value, 2)
        }
    
    return variations

def generate_executive_summary(variations):
    """
    G√©n√®re un r√©sum√© ex√©cutif de l'analyse
    
    Args:
        variations: Dict des variations calcul√©es
    
    Returns:
        String du r√©sum√© ex√©cutif
    """
    if not variations:
        return "Analyse incompl√®te - donn√©es insuffisantes pour g√©n√©rer un r√©sum√©."
    
    date_str = datetime.now().strftime("%d/%m/%Y")
    summary_parts = []
    
    for category, data in variations.items():
        variation = data["variation"]
        if abs(variation) >= 0.1:  # Variations significatives >= 100M‚Ç¨
            direction = "hausse" if variation > 0 else "baisse"
            summary_parts.append(f"{category}: {direction} de {abs(variation):.2f} Md‚Ç¨")
    
    if summary_parts:
        return f"Balance Sheet au {date_str} - Principales variations: {', '.join(summary_parts)}."
    else:
        return f"Balance Sheet au {date_str} - Variations mineures observ√©es (< 100M‚Ç¨)."

#######################################################################################################################################

#                           CONSUMPTION

#######################################################################################################################################

def create_consumption_analysis_grouped_only(dataframes):
    """
    Cr√©e l'analyse Consumption UNIQUEMENT par Groupe M√©tiers (sans d√©tail des m√©tiers)
    
    Args:
        dataframes: Dict contenant les DataFrames 'j' et 'jMinus1'
    
    Returns:
        Dict contenant les r√©sultats de l'analyse Consumption group√©e
    """
    try:
        logger.info("üíº Cr√©ation de l'analyse Consumption - Groupes M√©tiers uniquement")
        
        consumption_grouped = {}
        totals_by_group = {}
        
        # Traitement de chaque fichier
        for file_type, df in dataframes.items():
            logger.info(f"üîÑ Traitement Consumption group√© pour {file_type}")
            
            # V√©rification des colonnes requises
            required_cols = ["Top Conso", "LCR_ECO_GROUPE_METIERS", "LCR_ECO_IMPACT_LCR"]
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                logger.warning(f"‚ö†Ô∏è Colonnes manquantes pour Consumption {file_type}: {missing_cols}")
                continue
            
            # Filtrage des donn√©es (Top Conso = "O")
            df_filtered = df[df["Top Conso"] == "O"].copy()
            logger.info(f"üìã Apr√®s filtrage Top Conso='O': {len(df_filtered)} lignes")
            
            if len(df_filtered) == 0:
                logger.warning(f"‚ö†Ô∏è Aucune donn√©e avec Top Conso='O' pour Consumption {file_type}")
                continue
            
            # Pr√©paration des donn√©es
            df_filtered["LCR_ECO_IMPACT_LCR"] = pd.to_numeric(
                df_filtered["LCR_ECO_IMPACT_LCR"], errors='coerce'
            ).fillna(0)
            
            # Nettoyage des champs texte
            df_filtered["LCR_ECO_GROUPE_METIERS"] = df_filtered["LCR_ECO_GROUPE_METIERS"].astype(str).str.strip()
            
            # Groupement UNIQUEMENT par LCR_ECO_GROUPE_METIERS (pas de d√©tail m√©tier)
            grouped = df_filtered.groupby("LCR_ECO_GROUPE_METIERS")["LCR_ECO_IMPACT_LCR"].sum().reset_index()
            
            # Conversion en milliards
            grouped["LCR_ECO_IMPACT_LCR_Bn"] = (grouped["LCR_ECO_IMPACT_LCR"] / 1_000_000_000).round(3)
            
            consumption_grouped[file_type] = grouped
            
            # Calcul des totaux
            total_global = (df_filtered["LCR_ECO_IMPACT_LCR"].sum() / 1_000_000_000).round(3)
            
            totals_by_group[file_type] = {
                "total_global": total_global,
                "by_groupe_metiers": grouped.set_index("LCR_ECO_GROUPE_METIERS")["LCR_ECO_IMPACT_LCR_Bn"].to_dict(),
                "grouped_data": grouped
            }
            
            logger.info(f"‚úÖ Consumption group√© {file_type}: {len(grouped)} groupes, Total global = {total_global:.3f} Bn")
        
        # G√©n√©ration du HTML du tableau group√©
        consumption_html = generate_consumption_grouped_table_html(consumption_grouped)
        
        # Calcul des variations
        variations = calculate_consumption_grouped_variations(totals_by_group)
        
        # G√©n√©ration de l'analyse textuelle
        analysis_text = generate_consumption_grouped_analysis_text(variations, totals_by_group)
        
        return {
            "title": "LCR Consumption Analysis by Business Group (Summary)",
            "consumption_table_html": consumption_html,
            "variations": variations,
            "analysis_text": analysis_text,
            "metadata": {
                "analysis_date": datetime.now().isoformat(),
                "filter_applied": "Top Conso = 'O'",
                "grouping": ["LCR_ECO_GROUPE_METIERS"],  # Seulement groupe, pas m√©tier
                "measure": "LCR_ECO_IMPACT_LCR (Bn ‚Ç¨)",
                "view_type": "grouped_summary"
            }
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur cr√©ation analyse Consumption group√©e: {e}")
        return {
            "title": "Consumption Analysis Grouped - Erreur",
            "error": str(e),
            "consumption_table_html": "<p class='text-danger'>Erreur lors de la g√©n√©ration de l'analyse Consumption group√©e</p>"
        }

def generate_consumption_grouped_table_html(consumption_grouped):
    """
    G√©n√®re le HTML du tableau Consumption GROUP√â (sans d√©tail m√©tiers)
    """
    if len(consumption_grouped) < 2:
        return "<div class='alert alert-warning'>Donn√©es insuffisantes pour l'analyse Consumption group√©e</div>"
    
    grouped_j = consumption_grouped.get("j")
    grouped_j1 = consumption_grouped.get("jMinus1")
    
    if grouped_j is None or grouped_j1 is None:
        return "<div class='alert alert-danger'>Erreur: donn√©es Consumption group√©es manquantes</div>"
    
    # Fusion de tous les groupes m√©tiers
    all_groups = set()
    all_groups.update(grouped_j["LCR_ECO_GROUPE_METIERS"].tolist())
    all_groups.update(grouped_j1["LCR_ECO_GROUPE_METIERS"].tolist())
    
    # Cr√©ation des dictionnaires de lookup
    lookup_j = grouped_j.set_index("LCR_ECO_GROUPE_METIERS")["LCR_ECO_IMPACT_LCR_Bn"].to_dict()
    lookup_j1 = grouped_j1.set_index("LCR_ECO_GROUPE_METIERS")["LCR_ECO_IMPACT_LCR_Bn"].to_dict()
    
    html = """
    <table class="table table-bordered consumption-table">
        <thead>
            <tr>
                <th rowspan="2" class="align-middle">LCR Groupe M√©tiers</th>
                <th colspan="2" class="text-center header-j-minus-1">J-1 (Hier)</th>
                <th colspan="2" class="text-center header-j">J (Aujourd'hui)</th>
                <th rowspan="2" class="text-center header-variation align-middle">Variation<br>(Bn ‚Ç¨)</th>
            </tr>
            <tr>
                <th class="text-center header-j-minus-1">Consumption (Bn ‚Ç¨)</th>
                <th class="text-center header-j-minus-1">Part (%)</th>
                <th class="text-center header-j">Consumption (Bn ‚Ç¨)</th>
                <th class="text-center header-j">Part (%)</th>
            </tr>
        </thead>
        <tbody>
    """
    
    # Calcul des totaux globaux pour les pourcentages
    total_j1 = sum(lookup_j1.values())
    total_j = sum(lookup_j.values())
    
    # G√©n√©ration des lignes - UNE LIGNE PAR GROUPE M√âTIER
    for groupe_metiers in sorted(all_groups):
        value_j1 = lookup_j1.get(groupe_metiers, 0)
        value_j = lookup_j.get(groupe_metiers, 0)
        variation = value_j - value_j1
        
        # Calcul des pourcentages
        pct_j1 = (value_j1 / total_j1 * 100) if total_j1 != 0 else 0
        pct_j = (value_j / total_j * 100) if total_j != 0 else 0
        
        html += '<tr>'
        html += f'<td class="fw-bold">{groupe_metiers}</td>'
        
        # Valeurs J-1
        html += f'<td class="text-end numeric-value">{value_j1:.3f}</td>'
        html += f'<td class="text-end numeric-value">{pct_j1:.1f}%</td>'
        
        # Valeurs J
        html += f'<td class="text-end numeric-value">{value_j:.3f}</td>'
        html += f'<td class="text-end numeric-value">{pct_j:.1f}%</td>'
        
        # Variation
        css_class = "variation-positive" if variation > 0 else "variation-negative" if variation < 0 else ""
        sign = "+" if variation > 0 else ""
        html += f'<td class="text-end numeric-value {css_class}">{sign}{variation:.3f}</td>'
        
        html += '</tr>'
    
    # Ligne de total g√©n√©ral
    total_variation = total_j - total_j1
    css_class = "variation-positive" if total_variation > 0 else "variation-negative" if total_variation < 0 else ""
    sign = "+" if total_variation > 0 else ""
    
    html += f'''
        <tr class="total-row">
            <td class="text-end fw-bold">TOTAL G√âN√âRAL:</td>
            <td class="text-end fw-bold">{total_j1:.3f}</td>
            <td class="text-end fw-bold">100.0%</td>
            <td class="text-end fw-bold">{total_j:.3f}</td>
            <td class="text-end fw-bold">100.0%</td>
            <td class="text-end fw-bold {css_class}">{sign}{total_variation:.3f}</td>
        </tr>
    '''
    
    html += """
        </tbody>
    </table>
    """
    
    return html

def calculate_consumption_grouped_variations(totals_by_group):
    """Calcule les variations de consumption group√©e entre J et J-1"""
    if "j" not in totals_by_group or "jMinus1" not in totals_by_group:
        return {}
    
    j_data = totals_by_group["j"]
    j1_data = totals_by_group["jMinus1"]
    
    # Variation globale
    global_variation = j_data["total_global"] - j1_data["total_global"]
    
    # Variations par groupe m√©tiers
    group_variations = {}
    all_groups = set(j_data["by_groupe_metiers"].keys()) | set(j1_data["by_groupe_metiers"].keys())
    
    for group in all_groups:
        j_value = j_data["by_groupe_metiers"].get(group, 0)
        j1_value = j1_data["by_groupe_metiers"].get(group, 0)
        group_variations[group] = {
            "j_minus_1": j1_value,
            "j": j_value,
            "variation": round(j_value - j1_value, 3)
        }
    
    return {
        "global": {
            "j_minus_1": j1_data["total_global"],
            "j": j_data["total_global"],
            "variation": round(global_variation, 3)
        },
        "by_groupe_metiers": group_variations
    }

def generate_consumption_grouped_analysis_text(variations, totals_by_group):
    """G√©n√®re le texte d'analyse de la consumption group√©e"""
    if not variations or "global" not in variations:
        return "Analyse Consumption group√©e non disponible - donn√©es insuffisantes."
    
    global_data = variations["global"]
    date_str = datetime.now().strftime("March %d")
    
    # Analyse globale
    total_j = global_data["j"]
    variation = global_data["variation"]
    direction = "decrease" if variation < 0 else "increase"
    
    analysis = f"Summary view: on {date_str}, business groups have total consumption of {total_j:.2f} Bn, representing a {direction} of {abs(variation):.2f} Bn compared to yesterday."
    
    # Identification des principales variations par groupe (top 3)
    if "by_groupe_metiers" in variations:
        significant_variations = []
        sorted_variations = sorted(
            variations["by_groupe_metiers"].items(), 
            key=lambda x: abs(x[1]["variation"]), 
            reverse=True
        )
        
        for group, data in sorted_variations[:3]:  # Top 3 variations
            group_var = data["variation"]
            if abs(group_var) >= 0.05:  # Variations >= 50M
                sign = "-" if group_var < 0 else "+"
                significant_variations.append(f"{group} ({sign}{abs(group_var):.2f} Bn)")
        
        if significant_variations:
            if variation < 0:
                analysis += f" Main contributors to this decrease: {', '.join(significant_variations)}."
            else:
                analysis += f" Main drivers of this increase: {', '.join(significant_variations)}."
    
    return analysis


if __name__ == "__main__":
    print("üöÄ Steering ALM Metrics - Version Templates")
    print("üìä Interface: http://localhost:8000")
    print("üìÅ Templates: templates/index.html")
    print("üé® Styles: static/js/main.js")
    print("‚èπÔ∏è  Ctrl+C pour arr√™ter")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        reload=False,
        log_level="info"
    )